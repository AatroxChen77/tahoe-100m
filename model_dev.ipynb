{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy<2.0\n",
      "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install \"numpy<2.0\" --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scanpy\n",
      "  Downloading scanpy-1.11.2-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: anndata>=0.8 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from scanpy) (0.11.4)\n",
      "Requirement already satisfied: h5py>=3.7.0 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from scanpy) (3.14.0)\n",
      "Requirement already satisfied: joblib in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from scanpy) (1.4.2)\n",
      "Collecting legacy-api-wrap>=1.4.1 (from scanpy)\n",
      "  Downloading legacy_api_wrap-1.4.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: matplotlib>=3.7.5 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from scanpy) (3.10.0)\n",
      "Requirement already satisfied: natsort in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from scanpy) (8.4.0)\n",
      "Requirement already satisfied: networkx>=2.7.1 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from scanpy) (3.4.2)\n",
      "Collecting numba>=0.57.1 (from scanpy)\n",
      "  Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: numpy>=1.24.1 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from scanpy) (1.24.3)\n",
      "Requirement already satisfied: packaging>=21.3 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from scanpy) (25.0)\n",
      "Requirement already satisfied: pandas>=1.5.3 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from scanpy) (2.2.3)\n",
      "Collecting patsy!=1.0.0 (from scanpy)\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pynndescent>=0.5.13 (from scanpy)\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.1.3 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from scanpy) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.8.1 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from scanpy) (1.15.3)\n",
      "Collecting seaborn>=0.13.2 (from scanpy)\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting session-info2 (from scanpy)\n",
      "  Downloading session_info2-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting statsmodels>=0.14.4 (from scanpy)\n",
      "  Downloading statsmodels-0.14.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: tqdm in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from scanpy) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from scanpy) (4.14.0)\n",
      "Collecting umap-learn>=0.5.6 (from scanpy)\n",
      "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: array-api-compat!=1.5,>1.4 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from anndata>=0.8->scanpy) (1.12.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from matplotlib>=3.7.5->scanpy) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from matplotlib>=3.7.5->scanpy) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from matplotlib>=3.7.5->scanpy) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from matplotlib>=3.7.5->scanpy) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from matplotlib>=3.7.5->scanpy) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from matplotlib>=3.7.5->scanpy) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from matplotlib>=3.7.5->scanpy) (2.9.0.post0)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.57.1->scanpy)\n",
      "  Downloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from pandas>=1.5.3->scanpy) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from pandas>=1.5.3->scanpy) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.7.5->scanpy) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./miniconda3/envs/torch-gpu/lib/python3.11/site-packages (from scikit-learn>=1.1.3->scanpy) (3.5.0)\n",
      "Downloading scanpy-1.11.2-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading legacy_api_wrap-1.4.1-py3-none-any.whl (10.0 kB)\n",
      "Downloading numba-0.61.2-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading statsmodels-0.14.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
      "Downloading session_info2-0.1.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: session-info2, patsy, llvmlite, legacy-api-wrap, numba, statsmodels, seaborn, pynndescent, umap-learn, scanpy\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [scanpy]━━\u001b[0m \u001b[32m 9/10\u001b[0m [scanpy]]els]\n",
      "\u001b[1A\u001b[2KSuccessfully installed legacy-api-wrap-1.4.1 llvmlite-0.44.0 numba-0.61.2 patsy-1.0.1 pynndescent-0.5.13 scanpy-1.11.2 seaborn-0.13.2 session-info2-0.1.2 statsmodels-0.14.4 umap-learn-0.5.7\n"
     ]
    }
   ],
   "source": [
    "# reinstall scanpy\n",
    "!pip install scanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scanpy as sc\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Visualize latent space\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/torch-gpu/lib/python3.11/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "adata_100m=sc.read_h5ad(\"/home/ubuntu/anatoly-tahoe-100-texas/data/tahoe-100m_5M.h5ad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize each cell to 10,000 counts (CPM-like)\n",
    "sc.pp.normalize_total(adata_100m, target_sum=1e4)\n",
    "\n",
    "# Log-transform the data\n",
    "sc.pp.log1p(adata_100m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HVG selection (start with small subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Identify highly variable genes\n",
    "sc.pp.highly_variable_genes(adata_100m, n_top_genes=2000, subset=True, flavor=\"seurat\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get train and test idx\n",
    "train_idx, test_idx = train_test_split(adata_100m.obs.index, test_size=0.1, random_state=42)\n",
    "\n",
    "# data split with copy\n",
    "adata_train = adata_100m[train_idx].copy()\n",
    "adata_test = adata_100m[test_idx].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AdataCVAEWrapper(Dataset):\n",
    "    def __init__(self, adata, cat_features, cont_features):\n",
    "        self.X = adata.X  # keep expression data as sparse matrix\n",
    "        self.cat_data = pd.get_dummies(adata.obs[cat_features], drop_first=False).values.astype(np.float32)\n",
    "        self.cat_data = torch.from_numpy(self.cat_data)\n",
    "\n",
    "        cont = adata.obs[cont_features].values.astype(np.float32)\n",
    "        cont = (cont - cont.mean(axis=0)) / cont.std(axis=0)\n",
    "        self.cont_data = torch.from_numpy(cont)\n",
    "\n",
    "        self.cond = torch.cat([self.cat_data, self.cont_data], dim=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_row = torch.tensor(self.X[idx].toarray().squeeze(), dtype=torch.float32)\n",
    "        c = self.cond[idx]\n",
    "        return x_row, c\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self, input_dim, cond_dim, latent_dim=32):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim + cond_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(128, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(128, latent_dim)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim + cond_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_dim),\n",
    "            nn.ReLU()  # or identity / Sigmoid depending on your output\n",
    "        )\n",
    "\n",
    "    def encode(self, x, c):\n",
    "        h = self.encoder(torch.cat([x, c], dim=1))\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, c):\n",
    "        return self.decoder(torch.cat([z, c], dim=1))\n",
    "\n",
    "    def forward(self, x, c):\n",
    "        mu, logvar = self.encode(x, c)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z, c)\n",
    "        return recon_x, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# setup features\n",
    "cat_features=[\"drug\", \"cell_line_id\"]\n",
    "cont_features=[\"drug_conc\"]\n",
    "\n",
    "# create train and test datasets\n",
    "train_dataset = AdataCVAEWrapper(adata_train, cat_features, cont_features)\n",
    "test_dataset = AdataCVAEWrapper(adata_test, cat_features, cont_features)\n",
    "\n",
    "# create train and test loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900000, 2000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CVAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=2146, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (fc_mu): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (fc_logvar): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=178, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=2000, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup\n",
    "#dataset = AdataCVAEWrapper(adata_100m, cat_features=[\"drug\", \"cell_line_id\"], cont_features=[\"drug_conc\"])\n",
    "#loader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "\n",
    "# setup the model\n",
    "model = CVAE(input_dim=adata_train.n_vars, cond_dim=train_dataset.cond.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drug Info from PubChem\n",
    "\n",
    "We also provide the pubchem IDs for the compounds in Tahoe, this can be used to querry additional information as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model (10 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                             | 0/7813 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (128x62856 and 2146x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m x_batch = x_batch.to(device)\n\u001b[32m      7\u001b[39m c_batch = c_batch.to(device)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m recon_x, mu, logvar = model(x_batch, c_batch)\n\u001b[32m     10\u001b[39m loss = loss_function(recon_x, x_batch, mu, logvar)\n\u001b[32m     12\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-gpu/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-gpu/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mCVAE.forward\u001b[39m\u001b[34m(self, x, c)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, c):\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m     mu, logvar = \u001b[38;5;28mself\u001b[39m.encode(x, c)\n\u001b[32m     36\u001b[39m     z = \u001b[38;5;28mself\u001b[39m.reparameterize(mu, logvar)\n\u001b[32m     37\u001b[39m     recon_x = \u001b[38;5;28mself\u001b[39m.decode(z, c)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mCVAE.encode\u001b[39m\u001b[34m(self, x, c)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, c):\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     h = \u001b[38;5;28mself\u001b[39m.encoder(torch.cat([x, c], dim=\u001b[32m1\u001b[39m))\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fc_mu(h), \u001b[38;5;28mself\u001b[39m.fc_logvar(h)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-gpu/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-gpu/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-gpu/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = module(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-gpu/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-gpu/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/torch-gpu/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.linear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m.weight, \u001b[38;5;28mself\u001b[39m.bias)\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (128x62856 and 2146x512)"
     ]
    }
   ],
   "source": [
    "\n",
    "# simple example of model train\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for x_batch, c_batch in tqdm(loader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        c_batch = c_batch.to(device)\n",
    "\n",
    "        recon_x, mu, logvar = model(x_batch, c_batch)\n",
    "        loss = loss_function(recon_x, x_batch, mu, logvar)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drug Info from PubChem\n",
    "\n",
    "We also provide the pubchem IDs for the compounds in Tahoe, this can be used to querry additional information as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drug Info from PubChem\n",
    "\n",
    "We also provide the pubchem IDs for the compounds in Tahoe, this can be used to querry additional information as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_recon = []\n",
    "    all_original = []\n",
    "    all_latent = []\n",
    "    all_conditions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, c_batch in tqdm(test_loader):\n",
    "            x_batch = x_batch.to(device)\n",
    "            c_batch = c_batch.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            recon_x, mu, logvar = model(x_batch, c_batch)\n",
    "            loss = loss_function(recon_x, x_batch, mu, logvar)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Store results\n",
    "            all_recon.append(recon_x.cpu().numpy())\n",
    "            all_original.append(x_batch.cpu().numpy())\n",
    "            all_latent.append(mu.cpu().numpy())\n",
    "            all_conditions.append(c_batch.cpu().numpy())\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    all_recon = np.concatenate(all_recon, axis=0)\n",
    "    all_original = np.concatenate(all_original, axis=0)\n",
    "    all_latent = np.concatenate(all_latent, axis=0)\n",
    "    all_conditions = np.concatenate(all_conditions, axis=0)\n",
    "    \n",
    "    return {\n",
    "        'total_loss': total_loss,\n",
    "        'recon': all_recon,\n",
    "        'original': all_original,\n",
    "        'latent': all_latent,\n",
    "        'conditions': all_conditions\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run evalutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run evaluation\n",
    "eval_results = evaluate_model(model, test_loader, device)\n",
    "print(f\"Test Loss: {eval_results['total_loss']:.2f}\")\n",
    "\n",
    "# Calculate reconstruction metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Calculate MSE and R2 for each gene\n",
    "mse_per_gene = mean_squared_error(eval_results['original'], eval_results['recon'], multioutput='raw_values')\n",
    "r2_per_gene = r2_score(eval_results['original'], eval_results['recon'], multioutput='raw_values')\n",
    "\n",
    "print(f\"Average MSE per gene: {np.mean(mse_per_gene):.4f}\")\n",
    "print(f\"Average R2 per gene: {np.mean(r2_per_gene):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualise the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get the drug indices from the conditions\n",
    "drug_indices = np.argmax(eval_results['conditions'][:, :len(adata_test.obs['drug'].unique())], axis=1)\n",
    "drugs = adata_test.obs['drug'].unique()[drug_indices]\n",
    "\n",
    "# Plot first two dimensions of latent space colored by drug\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(eval_results['latent'][:, 0], \n",
    "                     eval_results['latent'][:, 1], \n",
    "                     c=drug_indices, \n",
    "                     cmap='tab20',\n",
    "                     alpha=0.6)\n",
    "plt.title('Latent Space Visualization (First 2 Dimensions)')\n",
    "plt.xlabel('Latent Dimension 1')\n",
    "plt.ylabel('Latent Dimension 2')\n",
    "plt.colorbar(scatter, label='Drug')\n",
    "plt.show()\n",
    "\n",
    "# Plot reconstruction vs original for a few random genes\n",
    "n_genes_to_plot = 4\n",
    "random_genes = np.random.choice(eval_results['original'].shape[1], n_genes_to_plot, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, gene_idx in enumerate(random_genes):\n",
    "    axes[idx].scatter(eval_results['original'][:, gene_idx], \n",
    "                     eval_results['recon'][:, gene_idx], \n",
    "                     alpha=0.5)\n",
    "    axes[idx].plot([0, 1], [0, 1], 'r--')  # Diagonal line\n",
    "    axes[idx].set_xlabel('Original Expression')\n",
    "    axes[idx].set_ylabel('Reconstructed Expression')\n",
    "    axes[idx].set_title(f'Gene {gene_idx}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
