{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465a77c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cavendishes\\.conda\\envs\\tahoe-cvae\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Creating parquet from Arrow format: 100%|██████████| 100/100 [00:03<00:00, 28.77ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 100/100 [00:03<00:00, 25.20ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 100/100 [00:04<00:00, 24.70ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 100/100 [00:04<00:00, 24.67ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 100/100 [00:05<00:00, 17.80ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 100/100 [00:06<00:00, 15.13ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 100/100 [00:06<00:00, 15.82ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 100/100 [00:06<00:00, 15.79ba/s]\n",
      " 85%|████████▍ | 846746/1000000 [26:52<05:32, 460.53it/s] '(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 6aa6009a-5d8b-4fe0-a7e4-02e75bd3d1a3)')' thrown while requesting GET https://huggingface.co/datasets/vevotx/Tahoe-100M/resolve/2dc57900b7981cfcf5e211527169a0b006546a95/data/train-00030-of-03388.parquet\n",
      "Retrying in 1s [Retry 1/5].\n",
      " 85%|████████▍ | 846746/1000000 [27:03<05:32, 460.53it/s]'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 27b2f94a-6a3a-4397-b773-1896014611b1)')' thrown while requesting GET https://huggingface.co/datasets/vevotx/Tahoe-100M/resolve/2dc57900b7981cfcf5e211527169a0b006546a95/data/train-00030-of-03388.parquet\n",
      "Retrying in 2s [Retry 2/5].\n",
      "Creating parquet from Arrow format: 100%|██████████| 100/100 [00:04<00:00, 24.21ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 100/100 [00:03<00:00, 25.05ba/s]\n",
      "100%|█████████▉| 999999/1000000 [31:28<00:00, 529.48it/s] \n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "streaming_ds = load_dataset(\"vevotx/Tahoe-100M\", split=\"train\", streaming=True)\n",
    "save_dir = \"tahoe_100w_parquet\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "batch = []\n",
    "batch_size = 100_000  # 每批写一次磁盘\n",
    "total = 1_000_000     # 总数\n",
    "n = 0\n",
    "file_idx = 0\n",
    "\n",
    "for sample in tqdm(streaming_ds, total=total):\n",
    "    batch.append(sample)\n",
    "    n += 1\n",
    "\n",
    "    if len(batch) == batch_size:\n",
    "        ds_batch = Dataset.from_list(batch)\n",
    "        ds_batch.to_parquet(f\"{save_dir}/part_{file_idx:02d}.parquet\")\n",
    "        batch = []\n",
    "        file_idx += 1\n",
    "\n",
    "    if n >= total:\n",
    "        break\n",
    "\n",
    "# 如果还有剩余\n",
    "if batch:\n",
    "    ds_batch = Dataset.from_list(batch)\n",
    "    ds_batch.to_parquet(f\"{save_dir}/part_{file_idx:02d}.parquet\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tahoe-cvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
